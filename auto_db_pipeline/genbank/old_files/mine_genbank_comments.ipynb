{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n## Right now you have all your code in this notebook. What you should be doing is whenever you have written a set of code you can group into a \\n## function, you should put that function in a .py file which you then import into your notebook. This way you will organise your code better and\\n## you won't end up with a notebook with 100+ cells where you can't figure out what you need to run and what is old code. \\n\\n## However, you will probably have to edit some of the .py scripts at some point, and with the default setting on jupyter this means you need to \\n## restart your kernel to then import the updated script. \\n\\n## To avoid this, include the 2 lines below after your imports above. This forces your notebook to autoreload your .py scripts everytime you edit them.\\n\\nload_ext autoreload\\n%autoreload 2\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import pandas as pd\n",
    "import copy\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import multiprocessing\n",
    "from numba import njit, jit\n",
    "\n",
    "Entrez.email = \"fabian.spoendlin@exeter.ox.ac.uk\" ## Move this to the init function of your genbank class\n",
    "\n",
    "\"\"\"\n",
    "## Right now you have all your code in this notebook. What you should be doing is whenever you have written a set of code you can group into a \n",
    "## function, you should put that function in a .py file which you then import into your notebook. This way you will organise your code better and\n",
    "## you won't end up with a notebook with 100+ cells where you can't figure out what you need to run and what is old code. \n",
    "\n",
    "## However, you will probably have to edit some of the .py scripts at some point, and with the default setting on jupyter this means you need to \n",
    "## restart your kernel to then import the updated script. \n",
    "\n",
    "## To avoid this, include the 2 lines below after your imports above. This forces your notebook to autoreload your .py scripts everytime you edit them.\n",
    "\n",
    "load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## It might be worth organising all the code as a class. This allows you too have all genbanksearch code in a single place and also easy to execute and\n",
    "## change. The below code is an example of how it could be done.\n",
    "\n",
    "\n",
    "class GenbankSearch:\n",
    "\n",
    "    def __init__(self, all_keyword_lists):\n",
    "    \n",
    "        self.search_query = get_genbank_search_query(all_keyword_lists)\n",
    "        \n",
    "        \n",
    "    def get_number_of_entries(self, db='protein'):\n",
    "        \"\n",
    "        search protein data base with keywords and find out how many entries are found\n",
    "        \"\n",
    "        handle = Entrez.esearch(db=db, term=self.search_query, retmax='2')\n",
    "        record = Entrez.read(handle)\n",
    "        self.number_of_entries = int(record['Count'])\n",
    "        print('number of entries:', number_of_entries)\n",
    "        \n",
    "    def get_entries(self, db='protein'):\n",
    "        \"\n",
    "        download all entries from search\n",
    "        \"\n",
    "        \n",
    "        handle = Entrez.esearch(db=db, term=self.search_query, retmax=self.number_of_entries)\n",
    "        record = Entrez.read(handle)\n",
    "\n",
    "        # 25 searches per second\n",
    "        a_handle =  Entrez.efetch(db=db, id=record['IdList'], rettype=\"gb\", retmode=\"xml\")\n",
    "        return Entrez.read(a_handle)\n",
    "        \n",
    "\n",
    "    def __call__(self, db='protein'):\n",
    "    \n",
    "        self.get_number_of_entries(db)\n",
    "        entries = self.get_entries(db)\n",
    "        \n",
    "        ## More steps\n",
    "   \n",
    "\n",
    "## The __init__ function allows you to set some values that won't change\n",
    "genbanksearch = GenbankSearch(all_keyword_lists)\n",
    "\n",
    "## The __call__ function allows you to run the class directly without specifying a specific function. \n",
    "## Within the __call__ function you should have the pipeline you want to be executed.\n",
    "\n",
    "genbanksearch('protein')\n",
    "genbanksearch('nucleotide')\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open('CoV-AbDab_181021.csv', 'r') as f:\n",
    "    CovAbDab = pd.read_csv(f)   \n",
    "\n",
    "# missing seqs in Cov abdab are ND, this can be protein seq -> replace with something thats not protein seq\n",
    "CovAbDab['VH or VHH'].replace(to_replace='ND', value='no sequence available', inplace=True)\n",
    "CovAbDab['VL'].replace(to_replace='ND', value='no sequence available', inplace=True)\n",
    "CovAbDab['VH or VHH'].fillna('no sequence available', inplace=True)\n",
    "CovAbDab['VL'].fillna('no sequence available', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protein search pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of entries: 9143\n"
     ]
    }
   ],
   "source": [
    "# perform keyword search\n",
    "\n",
    "# specify the terms used for the search\n",
    "search = '((Immunoglobulin[All Fields] OR antibody[All Fields] OR antibodies[All Fields] OR nanobody[All Fields] OR nanobodies[All Fields]) AND (COVID-19[All Fields] OR coronavirus[All Fields] OR Sars-Cov[All Fields] OR Mers-Cov[All Fields] OR SARS[All Fields] OR Sars-CoV-2[All Fields]) AND (neutralizing[All Fields] OR neutralize[All Fields] OR neutralisation[All Fields] OR bind[All Fields] OR inhibit[All Fields] OR anti-Sars-Cov-2[All Fields]))'\n",
    "\n",
    "\"\"\"\n",
    "## Changing the search query into a function with lists of keywords as input will allow you to be more flexible. \n",
    "## The following is an example, where the 'all_keyword_lists' variable should be coming from outside the whole mine genbank class.\n",
    "\n",
    "keyword_list1 = ['Immunoglobulin','antibody','antibodies','nanobody','nanobodies']\n",
    "keyword_list2 = ['COVID-19','coronavirus','Sars-Cov','Mers-Cov','SARS','Sars-CoV-2']\n",
    "keyword_list3 = ['neutralizing','neutralize','neutralisation','bind','inhibit','anti-Sars-Cov-2']\n",
    "\n",
    "all_keyword_lists = [keyword_list1, keyword_list2, keyword_list3]\n",
    "\n",
    "\n",
    "def get_genbank_search_query(all_keyword_lists):\n",
    "\n",
    "    search = []\n",
    "    for keyword_list in all_keyword_lists:\n",
    "        or_keywords = ' OR '.join([\"{}[All Fields]\".format(keyword) for keyword in keyword_list])\n",
    "\n",
    "        search.append('('+or_keywords+')')\n",
    "\n",
    "\n",
    "    return '('+' AND '.join(search)+')'\n",
    "\n",
    "search = get_genbank_search_query(all_keyword_lists)\n",
    "\"\"\"\n",
    "\n",
    "# search protein data base with keywords and find out how many entries are found\n",
    "handle = Entrez.esearch(db='protein', term=search, retmax='2')\n",
    "record = Entrez.read(handle)\n",
    "number_of_entries = int(record['Count'])\n",
    "print('number of entries:', number_of_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download all entries from search\n",
    "\n",
    "handle = Entrez.esearch(db='protein', term=search, retmax=25)#number_of_entries)\n",
    "record = Entrez.read(handle)\n",
    "\n",
    "# 25 searches per second\n",
    "protein_handle =  Entrez.efetch(db=\"protein\", id=record['IdList'], rettype=\"gb\", retmode=\"xml\")\n",
    "proteins = Entrez.read(protein_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mnon-precise type array(pyobject, 1d, C)\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of argument at <ipython-input-10-bb58127ff652> (7)\u001b[0m\n\u001b[1m\nFile \"<ipython-input-10-bb58127ff652>\", line 7:\u001b[0m\n\u001b[1mdef search_in_covabdab(aa_seqs, VH_arr, VL_arr, VH_found, VL_found, sequences_not_in_covabdab):\n    <source elided>\n\n\u001b[1m    sequences_not_in_covabdab = 0\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-bb58127ff652>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# run function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mVH_found\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVL_found\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences_not_in_covabdab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_in_covabdab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maa_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVH_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVL_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVH_found\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVL_found\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences_not_in_covabdab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# format results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/autodb/lib/python3.9/site-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    418\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0merror_rewrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'typing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;31m# Something unsupported is present in the user code, add help info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/autodb/lib/python3.9/site-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36merror_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    359\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0margtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mnon-precise type array(pyobject, 1d, C)\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of argument at <ipython-input-10-bb58127ff652> (7)\u001b[0m\n\u001b[1m\nFile \"<ipython-input-10-bb58127ff652>\", line 7:\u001b[0m\n\u001b[1mdef search_in_covabdab(aa_seqs, VH_arr, VL_arr, VH_found, VL_found, sequences_not_in_covabdab):\n    <source elided>\n\n\u001b[1m    sequences_not_in_covabdab = 0\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# compare found sequences to covab dab\n",
    "\n",
    "# use numba to speed up computation\n",
    "\"\"\"\n",
    "It needs to be set to nopython=True for it run fast. However, this gives some struggles with the code.\n",
    "\"\"\"\n",
    "\n",
    "@jit(nopython=True)\n",
    "def search_in_covabdab(aa_seqs, VH_arr, VL_arr, VH_found, VL_found, sequences_not_in_covabdab):\n",
    "\n",
    "    sequences_not_in_covabdab = 0\n",
    "\n",
    "    # loop throught aa seqs\n",
    "    for aa_seq in aa_seqs:\n",
    "        sequence_found = False\n",
    "\n",
    "        # loop throught covab dab entries\n",
    "        for i in range(len(VH_arr)):\n",
    "\n",
    "            # in case VH is in covab dab increase the VH count of this entry by 1\n",
    "            if VH_arr[i] in aa_seq:\n",
    "                VH_found[i] = VH_found[i] + 1\n",
    "                sequence_found = True\n",
    "\n",
    "            # in case VL is in covab dab increase the VL count of this entry by 1\n",
    "            if VL_arr[i] in aa_seq:\n",
    "                VL_found[i] = VL_found[i] + 1\n",
    "                sequence_found = True\n",
    "\n",
    "        # sequence that has no match with vh or vl is counted as a not found sequence\n",
    "        if not sequence_found:\n",
    "            sequences_not_in_covabdab = sequences_not_in_covabdab + 1\n",
    "\n",
    "        \n",
    "    return VH_found, VL_found, sequences_not_in_covabdab\n",
    "\n",
    "# prepare all variables for jit\n",
    "sequences_not_in_covabdab = 0\n",
    "VL_arr = CovAbDab['VL'].to_numpy()\n",
    "VH_arr = CovAbDab['VH or VHH'].to_numpy()\n",
    "VH_found = np.zeros((len(VH_arr)))\n",
    "VL_found = np.zeros((len(VL_arr)))\n",
    "aa_seqs = []\n",
    "for i in range(len(proteins)):\n",
    "    aa_seq = Seq(proteins[i]['GBSeq_sequence'])\n",
    "    aa_seqs.append(str.upper(str(aa_seq)))\n",
    "\n",
    "# run function\n",
    "VH_found, VL_found, sequences_not_in_covabdab = search_in_covabdab(aa_seqs, VH_arr, VL_arr, VH_found, VL_found, sequences_not_in_covabdab)\n",
    "\n",
    "# format results\n",
    "sequences_in_covabdab = len(proteins) - sequences_not_in_covabdab\n",
    "CovAbDab_stats_pr = copy.deepcopy(CovAbDab)\n",
    "CovAbDab_stats_pr['VH_found'] = VH_found\n",
    "CovAbDab_stats_pr['VL_found'] = VL_found\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print summary statistics\n",
    "\n",
    "if True:\n",
    "    print('total sequences assessed:', len(proteins))\n",
    "    print('number of genbank sequences not in covab dab:', sequences_not_in_covabdab)\n",
    "    print('number of genbank sequences found in covab dab:', sequences_in_covabdab)\n",
    "    print('match rate:', sequences_in_covabdab / len(proteins))\n",
    "    # if the total number of counts in VH and VL columns is higher than the genbank sequences that have a match in covab dab\n",
    "    # then a genbank sequence must have several matches in covab dab\n",
    "    print('number of genebank sequences that have multiple matches in covab dab:', (sum(CovAbDab_stats_pr['VH_found'])+sum(CovAbDab_stats_pr['VL_found'])-sequences_in_covabdab))\n",
    "    # if the number of genbank sequences with a match in covab dab is higher than the number of covab dab VH and VLs that were found\n",
    "    # then a number of genbank sequences must have matched to the same covab dab sequenc\n",
    "    # stat is wrong\n",
    "    print('number of genebank entries with non unique match in covab dab:', (sequences_in_covabdab - (len(CovAbDab_stats_pr.loc[(CovAbDab_stats_pr['VH_found'] > 0)]) + len(CovAbDab_stats_pr.loc[(CovAbDab_stats_pr['VL_found'] > 0)]))))\n",
    "    print('-------------')\n",
    "    print('total sequences in covab dab:', len(CovAbDab_stats_pr))\n",
    "    print('number of Covab Dab VH sequences found:', len(CovAbDab_stats_pr.loc[(CovAbDab_stats_pr['VH_found'] > 0)]))\n",
    "    print('number of Covab Dab VL sequences found:', len(CovAbDab_stats_pr.loc[(CovAbDab_stats_pr['VL_found'] > 0)]))\n",
    "    VH_VL_pairings = len(CovAbDab_stats_pr.loc[(CovAbDab_stats_pr['VH_found'] > 0) & (CovAbDab_stats_pr['VL_found'] > 0)])\n",
    "    print('number of Covab Dab VH VL pairings found:', VH_VL_pairings)\n",
    "    VH_or_VL = len(CovAbDab_stats_pr.loc[(CovAbDab_stats_pr['VH_found'] > 0) | (CovAbDab_stats_pr['VL_found'] > 0)])\n",
    "    print('number of Covab Dab entires where either VH or VL was found:', VH_or_VL)\n",
    "    print('-------------')\n",
    "    print('percentage of covab dab entries with pairing found:', VH_VL_pairings / len(CovAbDab_stats_pr) * 100 )\n",
    "    print('percentage of covab dab entries with either VL or VH found:', VH_or_VL / len(CovAbDab_stats_pr) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save stats\n",
    "\n",
    "if True:\n",
    "    with open('data/protein_search_stats.csv', 'r+') as fo:\n",
    "        fo.read()\n",
    "        fo.write(f'{search}, {len(CovAbDab_stats_pr)}, {sequences_not_in_covabdab}, {sequences_in_covabdab}, {sequences_in_covabdab / len(CovAbDab_stats_pr)}, {(sum(CovAbDab_stats_pr[\"VH_found\"]) + sum(CovAbDab_stats_pr[\"VL_found\"]) - sequences_in_covabdab)}, {(sequences_in_covabdab - (len(CovAbDab_stats_pr.loc[(CovAbDab_stats_pr[\"VH_found\"] > 0)])) + len(CovAbDab_stats_pr.loc[(CovAbDab_stats_pr[\"VL_found\"] > 0)]))}, {len(CovAbDab_stats_pr)}, {len(CovAbDab_stats_pr.loc[(CovAbDab_stats_pr[\"VH_found\"] > 0)])}, {len(CovAbDab_stats_pr.loc[(CovAbDab_stats_pr[\"VL_found\"] > 0)])}, {len(CovAbDab_stats_pr.loc[(CovAbDab_stats_pr[\"VH_found\"] > 0) & (CovAbDab_stats_pr[\"VL_found\"] > 0)])}, {len(CovAbDab_stats_pr.loc[(CovAbDab_stats_pr[\"VH_found\"] > 0) | (CovAbDab_stats_pr[\"VL_found\"] > 0)])}, {VH_VL_pairings / len(CovAbDab_stats_pr) * 100}, {VH_or_VL / len(CovAbDab_stats_pr) * 100}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nucleotide search pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of entries: 4305\n"
     ]
    }
   ],
   "source": [
    "# perform keyword search\n",
    "\n",
    "# specify the terms used for the search\n",
    "search = '((Immunoglobulin[All Fields] OR antibody[All Fields] OR antibodies[All Fields] OR nanobody[All Fields] OR nanobodies[All Fields]) AND (COVID-19[All Fields] OR coronavirus[All Fields] OR Sars-Cov[All Fields] OR Mers-Cov[All Fields] OR SARS[All Fields] OR Sars-CoV-2[All Fields]) AND (neutralizing[All Fields] OR neutralize[All Fields] OR neutralisation[All Fields] OR bind[All Fields] OR inhibit[All Fields] OR anti-Sars-Cov-2[All Fields]))'\n",
    "\n",
    "# search protein data base with keywords and find out how many entries are found\n",
    "handle = Entrez.esearch(db='nucleotide', term=search, retmax='2')\n",
    "record = Entrez.read(handle)\n",
    "number_of_entries = int(record['Count'])\n",
    "print('number of entries:', number_of_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "IncompleteRead",
     "evalue": "IncompleteRead(286 bytes read)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/auto-db-pipeline/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_readinto_chunked\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    595\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mchunk_left\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m                     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_readinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/auto-db-pipeline/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_safe_readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtotal_bytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m             \u001b[0mmvb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmvb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIncompleteRead\u001b[0m: IncompleteRead(0 bytes read, 1762 more expected)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8x/40q8fgwd2wg9ptnzw_b8cl480000gn/T/ipykernel_2247/4195458418.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 25 searches per second\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnucleotide_handle\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mEntrez\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nucleotide\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IdList'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrettype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"xml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mnucleotides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEntrez\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnucleotide_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/auto-db-pipeline/lib/python3.9/site-packages/Bio/Entrez/__init__.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(handle, validate, escape)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0mhandler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mescape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m     \u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/auto-db-pipeline/lib/python3.9/site-packages/Bio/Entrez/Parser.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, handle)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file should be opened in binary mode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexpat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExpatError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStartElementHandler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/auto-db-pipeline/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/auto-db-pipeline/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readinto_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/auto-db-pipeline/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_readinto_chunked\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtotal_bytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIncompleteRead\u001b[0m: IncompleteRead(286 bytes read)"
     ]
    }
   ],
   "source": [
    "# download all entries from search\n",
    "\n",
    "handle = Entrez.esearch(db='nucleotide', term=search, retmax=number_of_entries)\n",
    "record = Entrez.read(handle)\n",
    "\n",
    "# 25 searches per second\n",
    "nucleotide_handle =  Entrez.efetch(db=\"nucleotide\", id=record['IdList'], rettype=\"gb\", retmode=\"xml\")\n",
    "nucleotides = Entrez.read(nucleotide_handle)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compare found sequences to covab dab\n",
    "\n",
    "# use numba to speed up computation\n",
    "@jit\n",
    "def search_in_covabdab(aa_seqs, VH_arr, VL_arr, VH_found, VL_found, sequences_not_in_covabdab):\n",
    "\n",
    "    sequences_not_in_covabdab = 0\n",
    "\n",
    "    # loop throught aa seqs\n",
    "    for aa_seq in aa_seqs:\n",
    "        sequence_found = False\n",
    "\n",
    "        # loop throught covab dab entries\n",
    "        for i in range(len(VH_arr)):\n",
    "\n",
    "            # in case VH is in covab dab increase the VH count of this entry by 1\n",
    "            if VH_arr[i] in aa_seq:\n",
    "                VH_found[i] = VH_found[i] + 1\n",
    "                sequence_found = True\n",
    "\n",
    "            # in case VL is in covab dab increase the VL count of this entry by 1\n",
    "            if str(VL_arr[i]) in aa_seq:\n",
    "                VL_found[i] = VL_found[i] + 1\n",
    "                sequence_found = True\n",
    "\n",
    "        # sequence that has no match with vh or vl is counted as a not found sequence\n",
    "        if not sequence_found:\n",
    "            sequences_not_in_covabdab = sequences_not_in_covabdab + 1\n",
    "\n",
    "        \n",
    "    return VH_found, VL_found, sequences_not_in_covabdab\n",
    "\n",
    "# prepare all variables for jit\n",
    "sequences_not_in_covabdab = 0\n",
    "VL_arr = CovAbDab['VL'].to_numpy()\n",
    "VH_arr = CovAbDab['VH or VHH'].to_numpy()\n",
    "VH_found = np.zeros((len(VH_arr)))\n",
    "VL_found = np.zeros((len(VL_arr)))\n",
    "aa_seqs = []\n",
    "for i in range(len(nucleotides)):\n",
    "    nt_seq = Seq(nucleotides[i]['GBSeq_sequence'])\n",
    "    lenght_sequence = len(nt_seq)\n",
    "    remove_bases = lenght_sequence % 3\n",
    "    if remove_bases > 0:\n",
    "        nt_seq = nt_seq[:-remove_bases]\n",
    "    aa_seqs.append(str(nt_seq.translate()))\n",
    "\n",
    "# run function\n",
    "VH_found, VL_found, sequences_not_in_covabdab = search_in_covabdab(aa_seqs, VH_arr, VL_arr, VH_found, VL_found, sequences_not_in_covabdab)\n",
    "\n",
    "# format results\n",
    "sequences_in_covabdab = len(nucleotides) - sequences_not_in_covabdab\n",
    "CovAbDab_stats_nt= copy.deepcopy(CovAbDab)\n",
    "CovAbDab_stats_nt['VH_found'] = VH_found\n",
    "CovAbDab_stats_nt['VL_found'] = VL_found\n",
    "\n",
    "\n",
    "\n",
    "#print statistics\n",
    "\n",
    "if True:\n",
    "    print('total sequences assessed:', len(nucleotides))\n",
    "    print('number of genbank sequences not in covab dab:', sequences_not_in_covabdab)\n",
    "    print('number of genbank sequences found in covab dab:', sequences_in_covabdab)\n",
    "    print('match rate:', sequences_in_covabdab / len(nucleotides))\n",
    "    # if the total number of counts in VH and VL columns is higher than the genbank sequences that have a match in covab dab\n",
    "    # then a genbank sequence must have several matches in covab dab\n",
    "    print('number of genebank sequences that have multiple matches in covab dab:', (sum(CovAbDab_stats_nt['VH_found'])+sum(CovAbDab_stats_nt['VL_found'])-sequences_in_covabdab))\n",
    "    # if the number of genbank sequences with a match in covab dab is higher than the number of covab dab VH and VLs that were found\n",
    "    # then a number of genbank sequences must have matched to the same covab dab sequenc\n",
    "    print('number of genebank entries with non unique match in covab dab:', (sequences_in_covabdab - (len(CovAbDab_stats_nt.loc[(CovAbDab_stats_nt['VH_found'] > 0)]) + len(CovAbDab_stats_nt.loc[(CovAbDab_stats_nt['VL_found'] > 0)]))))\n",
    "    print('-------------')\n",
    "    print('total sequences in covab dab:', len(CovAbDab_stats_nt))\n",
    "    print('number of Covab Dab VH sequences found:', len(CovAbDab_stats_nt.loc[(CovAbDab_stats_nt['VH_found'] > 0)]))\n",
    "    print('number of Covab Dab VL sequences found:', len(CovAbDab_stats_nt.loc[(CovAbDab_stats_nt['VL_found'] > 0)]))\n",
    "    VH_VL_pairings = len(CovAbDab_stats_nt.loc[(CovAbDab_stats_nt['VH_found'] > 0) & (CovAbDab_stats_nt['VL_found'] > 0)])\n",
    "    print('number of Covab Dab VH VL pairings found:', VH_VL_pairings)\n",
    "    VH_or_VL = len(CovAbDab_stats_nt.loc[(CovAbDab_stats_nt['VH_found'] > 0) | (CovAbDab_stats_nt['VL_found'] > 0)])\n",
    "    print('number of Covab Dab entires where either VH or VL was found:', VH_or_VL)\n",
    "    print('-------------')\n",
    "    print('percentage of covab dab entries with pairing found:', VH_VL_pairings / len(CovAbDab_stats_nt) * 100 )\n",
    "    print('percentage of covab dab entries with either VL or VH found:', VH_or_VL / len(CovAbDab_stats_nt) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error if some of the genbank entries are to big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save statistics\n",
    "\n",
    "if False:\n",
    "    with open('data/nucleotide_search_stats.csv', 'r+') as fo:\n",
    "        fo.read()\n",
    "        fo.write(f'{search}, {len(nucleotides)}, {sequences_not_in_covabdab }, {sequences_in_covabdab }, {sequences_in_covabdab / len(nucleotides)}, {(sum(CovAbDab_stats[\"VH_found\"]) + sum(CovAbDab_stats[\"VL_found\"]) - sequences_in_covabdab)}, {(sequences_in_covabdab - (len(CovAbDab_stats.loc[(CovAbDab_stats[\"VH_found\"] > 0)])) + len(CovAbDab_stats.loc[(CovAbDab_stats[\"VL_found\"] > 0)]))}, {len(CovAbDab_stats)}, {len(CovAbDab_stats.loc[(CovAbDab_stats[\"VH_found\"] > 0)])}, {len(CovAbDab_stats.loc[(CovAbDab_stats[\"VL_found\"] > 0)])}, {len(CovAbDab_stats.loc[(CovAbDab_stats[\"VH_found\"] > 0) & (CovAbDab_stats[\"VL_found\"] > 0)])}, {len(CovAbDab_stats.loc[(CovAbDab_stats[\"VH_found\"] > 0) | (CovAbDab_stats[\"VL_found\"] > 0)])}, {VH_VL_pairings / len(CovAbDab_stats) * 100}, {VH_or_VL / len(CovAbDab_stats) * 100}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search both protein and nucelotide - much slower than the individual search first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of proteins: 8979\n",
      "number of nucelotides: 4305\n"
     ]
    }
   ],
   "source": [
    "# perform keyword search\n",
    "\n",
    "# specify the terms used for the search\n",
    "search = '((Immunoglobulin[All Fields] OR antibody[All Fields] OR antibodies[All Fields] OR nanobody[All Fields] OR nanobodies[All Fields]) AND (COVID-19[All Fields] OR coronavirus[All Fields] OR Sars-Cov[All Fields] OR Mers-Cov[All Fields] OR SARS[All Fields] OR Sars-CoV-2[All Fields]) AND (neutralizing[All Fields] OR neutralize[All Fields] OR neutralisation[All Fields] OR bind[All Fields] OR inhibit[All Fields] OR anti-Sars-Cov-2[All Fields]))'\n",
    "\n",
    "# search protein data base with keywords and find out how many entries are found\n",
    "handle_pr = Entrez.esearch(db='protein', term=search, retmax='2')\n",
    "record_pr = Entrez.read(handle_pr)\n",
    "number_of_proteins = int(record_pr['Count'])\n",
    "print('number of proteins:', number_of_proteins)\n",
    "\n",
    "\n",
    "# search protein data base with keywords and find out how many entries are found\n",
    "handle_nt = Entrez.esearch(db='nucleotide', term=search, retmax='2')\n",
    "record_nt = Entrez.read(handle_nt)\n",
    "number_of_nucleotides = int(record_nt['Count'])\n",
    "print('number of nucelotides:', number_of_nucleotides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IncompleteRead",
     "evalue": "IncompleteRead(1603 bytes read)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/auto-db-pipeline/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_readinto_chunked\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    595\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mchunk_left\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m                     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_readinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/auto-db-pipeline/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_safe_readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtotal_bytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m             \u001b[0mmvb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmvb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIncompleteRead\u001b[0m: IncompleteRead(0 bytes read, 445 more expected)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8x/40q8fgwd2wg9ptnzw_b8cl480000gn/T/ipykernel_2247/4084350237.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0msearch_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdatabase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'protein'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'nucleotide'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mdownload_entries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# run searches on multiprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/8x/40q8fgwd2wg9ptnzw_b8cl480000gn/T/ipykernel_2247/4084350237.py\u001b[0m in \u001b[0;36mdownload_entries\u001b[0;34m(database)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# 25 searches per second\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mentry_handle\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mEntrez\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nucleotide\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IdList'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrettype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"xml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEntrez\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0msearch_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/auto-db-pipeline/lib/python3.9/site-packages/Bio/Entrez/__init__.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(handle, validate, escape)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0mhandler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mescape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m     \u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/auto-db-pipeline/lib/python3.9/site-packages/Bio/Entrez/Parser.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, handle)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file should be opened in binary mode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexpat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExpatError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStartElementHandler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/auto-db-pipeline/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/auto-db-pipeline/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readinto_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/auto-db-pipeline/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_readinto_chunked\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtotal_bytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIncompleteRead\u001b[0m: IncompleteRead(1603 bytes read)"
     ]
    }
   ],
   "source": [
    "# download all entries from search\n",
    "\n",
    "# ----> remove function to make it faster\n",
    "def download_entries(database):\n",
    "\n",
    "    if database == 'protein':\n",
    "        handle = Entrez.esearch(db='protein', term=search, retmax=number_of_proteins)\n",
    "        record = Entrez.read(handle)\n",
    "\n",
    "        # 25 searches per second\n",
    "        entry_handle =  Entrez.efetch(db=\"protein\", id=record['IdList'], rettype=\"gb\", retmode=\"xml\")\n",
    "        entries = Entrez.read(entry_handle)\n",
    "\n",
    "    if database == 'nucleotide':\n",
    "        handle = Entrez.esearch(db='nucleotide', term=search, retmax=number_of_nucleotides)\n",
    "        record = Entrez.read(handle)\n",
    "\n",
    "        # 25 searches per second\n",
    "        entry_handle =  Entrez.efetch(db=\"nucleotide\", id=record['IdList'], rettype=\"gb\", retmode=\"xml\")\n",
    "        entries = Entrez.read(entry_handle)\n",
    "\n",
    "    search_results[database] = entries\n",
    "\n",
    "\n",
    "search_results = {}\n",
    "for database in ['protein','nucleotide']:\n",
    "    download_entries(database)\n",
    "\n",
    "# run searches on multiprocessing\n",
    "#pool = multiprocessing.Pool()\n",
    "#pool.map(download_entries, ['protein', 'nucleotide'])\n",
    "#pool.close()\n",
    "\n",
    "# compare found sequences to covab dab\n",
    "\n",
    "# use numba to speed up computation\n",
    "@jit\n",
    "def search_in_covabdab(aa_seqs, VH_arr, VL_arr, VH_found, VL_found, sequences_not_in_covabdab):\n",
    "\n",
    "    # loop throught aa seqs\n",
    "    for aa_seq in aa_seqs:\n",
    "        sequence_found = False\n",
    "\n",
    "        # loop throught covab dab entries\n",
    "        for i in range(len(VH_arr)):\n",
    "\n",
    "            # in case VH is in covab dab increase the VH count of this entry by 1\n",
    "            if VH_arr[i] in aa_seq:\n",
    "                VH_found[i] = VH_found[i] + 1\n",
    "                sequence_found = True\n",
    "\n",
    "            # in case VL is in covab dab increase the VL count of this entry by 1\n",
    "            if str(VL_arr[i]) in aa_seq:\n",
    "                VL_found[i] = VL_found[i] + 1\n",
    "                sequence_found = True\n",
    "\n",
    "        # sequence that has no match with vh or vl is counted as a not found sequence\n",
    "        if not sequence_found:\n",
    "            sequences_not_in_covabdab = sequences_not_in_covabdab + 1\n",
    "\n",
    "        \n",
    "    return VH_found, VL_found, sequences_not_in_covabdab\n",
    "\n",
    "# prepare all variables for jit\n",
    "VL_arr = CovAbDab['VL'].to_numpy()\n",
    "VH_arr = CovAbDab['VH or VHH'].to_numpy()\n",
    "VH_found_pr = np.zeros((len(VH_arr)))\n",
    "VL_found_pr = np.zeros((len(VL_arr)))\n",
    "VH_found_nt = np.zeros((len(VH_arr)))\n",
    "VL_found_nt = np.zeros((len(VL_arr)))\n",
    "\n",
    "\n",
    "sequences_not_in_covabdab_nt = 0\n",
    "aa_seqs_nt = []\n",
    "for i in range(len(search_results['nucleotide'])):\n",
    "    nt_seq = Seq(search_results['nucleotide'][i]['GBSeq_sequence'])\n",
    "    lenght_sequence = len(nt_seq)\n",
    "    remove_bases = lenght_sequence % 3\n",
    "    if remove_bases > 0:\n",
    "        nt_seq = nt_seq[:-remove_bases]\n",
    "    aa_seqs_nt.append(str(nt_seq.translate()))\n",
    "\n",
    "# prepare all variables for jit\n",
    "sequences_not_in_covabdab_pr = 0\n",
    "aa_seqs_pr = []\n",
    "for i in range(len(search_results['protein'])):\n",
    "    aa_seq = Seq(search_results['protein'][i]['GBSeq_sequence'])\n",
    "    aa_seqs_pr.append(str.upper(str(aa_seq)))\n",
    "\n",
    "# run function\n",
    "VH_found_nt, VL_found_nt, sequences_not_in_covabdab_nt = search_in_covabdab(aa_seqs_nt, VH_arr, VL_arr, VH_found_nt, VL_found_nt, sequences_not_in_covabdab_nt)\n",
    "VH_found_pr, VL_found_pr, sequences_not_in_covabdab_pr = search_in_covabdab(aa_seqs_pr, VH_arr, VL_arr, VH_found_pr, VL_found_pr, sequences_not_in_covabdab_pr)\n",
    "\n",
    "# format results\n",
    "sequences_in_covabdab_nt = len(search_results['nucleotide']) - sequences_not_in_covabdab_nt\n",
    "sequences_in_covabdab_pr = len(search_results['protein']) - sequences_not_in_covabdab_pr\n",
    "total_sequences = len(search_results['nucleotide']) + len(search_results['protein'])\n",
    "total_sequences_in_covabdab = sequences_in_covabdab_pr + sequences_in_covabdab_nt\n",
    "total_sequences_not_in_covabdab = sequences_not_in_covabdab_nt + sequences_not_in_covabdab_pr\n",
    "CovAbDab_stats= copy.deepcopy(CovAbDab)\n",
    "\n",
    "CovAbDab_stats['VH_found_nucleotide'] = VH_found_nt\n",
    "CovAbDab_stats['VL_found_nucleotide'] = VL_found_nt\n",
    "CovAbDab_stats['VH_found_protein'] = VH_found_pr\n",
    "CovAbDab_stats['VL_found_protein'] = VL_found_pr\n",
    "CovAbDab_stats['VH_found'] = VH_found_pr + VH_found_nt # total\n",
    "CovAbDab_stats['VL_found'] = VL_found_pr + VL_found_nt # total\n",
    "\n",
    "\n",
    "\n",
    "#print statistics\n",
    "\n",
    "if True:\n",
    "    print('total sequences assessed:', total_sequences)\n",
    "    print('number of genbank sequences not in covab dab:', total_sequences_not_in_covabdab)\n",
    "    print('number of genbank sequences found in covab dab:', total_sequences_in_covabdab)\n",
    "    print('match rate:', total_sequences_in_covabdab / total_sequences)\n",
    "    # if the total number of counts in VH and VL columns is higher than the genbank sequences that have a match in covab dab\n",
    "    # then a genbank sequence must have several matches in covab dab\n",
    "    print('number of genebank sequences that have multiple matches in covab dab:', (sum(CovAbDab_stats['VH_found'])+sum(CovAbDab_stats['VL_found'])-total_sequences_in_covabdab))\n",
    "    # if the number of genbank sequences with a match in covab dab is higher than the number of covab dab VH and VLs that were found\n",
    "    # then a number of genbank sequences must have matched to the same covab dab sequenc\n",
    "    print('number of genebank entries with non unique match in covab dab:', (total_sequences_in_covabdab - (len(CovAbDab_stats.loc[(CovAbDab_stats['VH_found'] > 0)]) + len(CovAbDab_stats.loc[(CovAbDab_stats['VL_found'] > 0)]))))\n",
    "    print('-------------')\n",
    "    print('total sequences in covab dab:', len(CovAbDab_stats))\n",
    "    print('number of Covab Dab VH sequences found based on nucleotide:', len(CovAbDab_stats.loc[(CovAbDab_stats['VH_found_nucleotide'] > 0)]))\n",
    "    print('number of Covab Dab VL sequences found based on nucleotide:', len(CovAbDab_stats.loc[(CovAbDab_stats['VL_found_nucleotide'] > 0)]))\n",
    "    print('number of Covab Dab VH sequences found based on protein:', len(CovAbDab_stats.loc[(CovAbDab_stats['VH_found_protein'] > 0)]))\n",
    "    print('number of Covab Dab VL sequences found based on protein:', len(CovAbDab_stats.loc[(CovAbDab_stats['VL_found_protein'] > 0)]))\n",
    "    print('number of Covab Dab VH sequences found total:', len(CovAbDab_stats.loc[(CovAbDab_stats['VH_found'] > 0)]))\n",
    "    print('number of Covab Dab VL sequences found total:', len(CovAbDab_stats.loc[(CovAbDab_stats['VL_found'] > 0)]))\n",
    "    VH_VL_pairings = len(CovAbDab_stats.loc[(CovAbDab_stats['VH_found'] > 0) & (CovAbDab_stats['VL_found'] > 0)])\n",
    "    print('number of Covab Dab VH VL pairings found:', VH_VL_pairings)\n",
    "    VH_or_VL = len(CovAbDab_stats.loc[(CovAbDab_stats['VH_found'] > 0) | (CovAbDab_stats['VL_found'] > 0)])\n",
    "    print('number of Covab Dab entires where either VH or VL was found:', VH_or_VL)\n",
    "    print('-------------')\n",
    "    print('percentage of covab dab entries with pairing found:', VH_VL_pairings / len(CovAbDab_stats) * 100 )\n",
    "    print('percentage of covab dab entries with either VL or VH found:', VH_or_VL / len(CovAbDab_stats) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save statistics\n",
    "\n",
    "if True:\n",
    "    with open('data/protein_nucleotide_search_stats.csv', 'r+') as fo:\n",
    "        fo.read()\n",
    "        fo.write(f'{search}, {total_sequences}, {total_sequences_not_in_covabdab}, {total_sequences_in_covabdab}, {total_sequences_in_covabdab / total_sequences}, {(sum(CovAbDab_stats[\"VH_found\"])+sum(CovAbDab_stats[\"VL_found\"])-total_sequences_in_covabdab)}, {total_sequences_in_covabdab - (len(CovAbDab_stats.loc[(CovAbDab_stats[\"VH_found\"] > 0)]) + len(CovAbDab_stats.loc[(CovAbDab_stats[\"VL_found\"] > 0)]))}, {len(CovAbDab_stats)}, {len(CovAbDab_stats.loc[(CovAbDab_stats[\"VH_found\"] > 0)])}, {len(CovAbDab_stats.loc[(CovAbDab_stats[\"VL_found\"] > 0)])}, {len(CovAbDab_stats.loc[(CovAbDab_stats[\"VH_found\"] > 0) & (CovAbDab_stats[\"VL_found\"] > 0)])}, {len(CovAbDab_stats.loc[(CovAbDab_stats[\"VH_found\"] > 0) | (CovAbDab_stats[\"VL_found\"] > 0)])}, {VH_VL_pairings / len(CovAbDab_stats) * 100}, {VH_or_VL / len(CovAbDab_stats) * 100}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this search the nucleotide search does not find any new sequences compared to the protein search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next tasks\n",
    "1. optimise keywords to find more sequences\n",
    "2. look at proteins found in genbank that are not in covab dab, are these false positives or relevant antibodies missing from covab dab\n",
    "3. find a way to combine heavy and light chain sequnce\n",
    "4. extract all necesary info\n",
    "5. filter for false positives\n",
    "6. extend to other databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f5cb82b301b87eef88325f480de257324ba8b611cc1a51609875e0120daba8a9"
  },
  "kernelspec": {
   "display_name": "autodb",
   "language": "python",
   "name": "autodb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
