{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e13cdc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:paperscraper.load_dumps:Loaded biorxiv dump with 190584 entries\n",
      "INFO:paperscraper.load_dumps:Loaded chemrxiv dump with 10442 entries\n",
      "INFO:paperscraper.load_dumps:Loaded medrxiv dump with 33177 entries\n"
     ]
    },
    {
     "ename": "ChunkedEncodingError",
     "evalue": "(\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/autodb/lib/python3.9/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 16: b''",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidChunkLength\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/autodb/lib/python3.9/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                 \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autodb/lib/python3.9/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_chunk_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autodb/lib/python3.9/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    700\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mInvalidChunkLength\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidChunkLength\u001b[0m: InvalidChunkLength(got length b'', 0 bytes read)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/autodb/lib/python3.9/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autodb/lib/python3.9/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autodb/lib/python3.9/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_response\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autodb/lib/python3.9/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autodb/lib/python3.9/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m                 \u001b[0;31m# This includes IncompleteRead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mProtocolError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Connection broken: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProtocolError\u001b[0m: (\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mChunkedEncodingError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15558/2973670699.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    145\u001b[0m              \u001b[0;34m'gene'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epitope'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'receptor-binding domain'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rbd'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m              'spike protein', 'VHH']\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0mpapers_and_preprints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpubmed_papers_and_pt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjsonl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_15558/2973670699.py\u001b[0m in \u001b[0;36mpubmed_papers_and_pt\u001b[0;34m(keywords, fields, start_date, end_date, txt, jsonl, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mend_date\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEnd\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mSame\u001b[0m \u001b[0mnotation\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m     papers = search_pubmed_papers(keywords, fields, start_date, end_date,\n\u001b[0m\u001b[1;32m    106\u001b[0m                                   *args, **kwargs)\n\u001b[1;32m    107\u001b[0m     papers_pt = search_pubmed_papers(keywords+['AND preprint[pt]'],\n",
      "\u001b[0;32m/tmp/ipykernel_15558/2973670699.py\u001b[0m in \u001b[0;36msearch_pubmed_papers\u001b[0;34m(keywords, fields, start_date, end_date, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mkeywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     )\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mpapers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pubmed_papers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpapers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autodb/lib/python3.9/site-packages/paperscraper/pubmed/pubmed.py\u001b[0m in \u001b[0;36mget_pubmed_papers\u001b[0;34m(query, fields, max_results, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \"\"\"\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPUBMED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mget_mails\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"emails\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autodb/lib/python3.9/site-packages/pymed/api.py\u001b[0m in \u001b[0;36m_getArticles\u001b[0;34m(self, article_ids)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# Make the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         response = self._get(\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/entrez/eutils/efetch.fcgi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"xml\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/autodb/lib/python3.9/site-packages/pymed/api.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, url, parameters, output)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Make the request to PubMed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{BASE_URL}{url}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# Check for any errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autodb/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autodb/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autodb/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autodb/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autodb/lib/python3.9/site-packages/requests/models.py\u001b[0m in \u001b[0;36mcontent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    834\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autodb/lib/python3.9/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    759\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mContentDecodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mChunkedEncodingError\u001b[0m: (\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))"
     ]
    }
   ],
   "source": [
    "from typing import List, Union\n",
    "from paperscraper.pubmed import get_query_from_keywords_and_date\n",
    "from paperscraper.pubmed import get_pubmed_papers\n",
    "\n",
    "\n",
    "def search_pubmed_papers(\n",
    "    keywords: List[Union[str, List[str]]]\n",
    "    = [['SARS-CoV-2', 'COVID-19', 'coronavirus', 'SARS-CoV', 'MERS-CoV',\n",
    "        'SARS'],\n",
    "        ['antibody', 'antibodies', 'nanobody', 'immunoglobulin', 'MAb',\n",
    "         'nanobodies'],\n",
    "        ['neutralizing', 'neutralize', 'neutralization', 'bind', 'binding',\n",
    "         'inhibit', 'targeting'],\n",
    "        ['heavy chain', 'complementarity determining region', 'gene',\n",
    "         'epitope', 'receptor-binding domain', 'rbd', 'spike protein', 'VHH']],\n",
    "    fields: List = [\"title\", \"authors\", \"date\", \"abstract\", \"journal\", \"doi\"],\n",
    "    start_date: str = \"None\",\n",
    "    end_date: str = \"None\",\n",
    "    *args,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Combines get_pubmed_papers and dump_papers.\n",
    "    For default setting, just import this function and use\n",
    "    search_pubmed_papers()\n",
    "    Returns:\n",
    "        A list of dictionaries, each containing the paper's\n",
    "         [\"title\", \"authors\", \"date\", \"abstract\", \"journal\", \"doi\"]\n",
    "\n",
    "    Args:\n",
    "        keywords (List[Union[str, List[str]]]): List of keywords to request\n",
    "            pubmed API. The outer list level will be considered as AND\n",
    "            separated keys, the inner level as OR separated.\n",
    "        fields (List, optional): List of strings with fields to keep in output.\n",
    "            Defaults to ['title', 'authors', 'date', 'abstract',\n",
    "            'journal', 'doi'].\n",
    "            NOTE: If 'emails' is passed, an attempt is made to extract author\n",
    "            mail addresses.\n",
    "        start_date (str): Start date for the search. Needs to be in format:\n",
    "            YYYY/MM/DD, e.g. '2020/07/20'. Defaults to 'None', i.e. no specific\n",
    "            dates are used.\n",
    "        end_date (str): End date for the search. Same notation as start_date.\n",
    "    \"\"\"\n",
    "    # Translate keywords into query.\n",
    "    query = get_query_from_keywords_and_date(\n",
    "        keywords, start_date=start_date, end_date=end_date\n",
    "    )\n",
    "    papers = get_pubmed_papers(query, fields, *args, **kwargs)\n",
    "    return papers\n",
    "\n",
    "\n",
    "def dump_papers(papers, filepath: str) -> None:\n",
    "    \"\"\"\n",
    "    Receives a list of dicts, one dict per paper and dumps it into a .jsonl\n",
    "    file with one paper per line.\n",
    "    Args:\n",
    "        papers (list[dict]): List of papers\n",
    "        filepath (str): Path to dump the papers.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(filepath, \"w\") as f:\n",
    "        for paper in papers:\n",
    "            f.write(str(paper) + \"\\n\")\n",
    "\n",
    "\n",
    "def pubmed_papers_and_pt(\n",
    "    keywords: List[Union[str, List[str]]]\n",
    "    = [['SARS-CoV-2', 'COVID-19', 'coronavirus', 'SARS-CoV', 'MERS-CoV',\n",
    "        'SARS'],\n",
    "        ['antibody', 'antibodies', 'nanobody', 'immunoglobulin',\n",
    "         'nanobodies'],\n",
    "        ['neutralizing', 'neutralize', 'neutralization', 'bind', 'binding',\n",
    "         'inhibit', 'targeting', 'neutralising', 'neutralise', 'neutralisation'],\n",
    "        ['heavy chain', 'complementarity determining region', 'gene',\n",
    "         'epitope', 'receptor', 'rbd', 'spike protein', 'VHH', 'domain']],\n",
    "    fields: List = [\"title\", \"authors\", \"date\", \"abstract\", \"journal\", \"doi\"],\n",
    "    start_date: str = \"None\",\n",
    "    end_date: str = \"None\",\n",
    "    txt: bool = False,\n",
    "    jsonl: bool = False,\n",
    "    *args,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Search for papers and preprints on PubMed\n",
    "    Returns:\n",
    "        A list of dictionaries, each containing the paper's\n",
    "         [\"title\", \"authors\", \"date\", \"abstract\", \"journal\", \"doi\"]\n",
    "        AND/OR files containing relevant information\n",
    "\n",
    "    Args:\n",
    "        keywords (List[Union[str, List[str]]],optional): List of keywords to\n",
    "            request pubmed API. The outer list level will be considered as AND\n",
    "            separated keys, the inner level as OR separated.\n",
    "        fields (List, optional): List of strings with fields to keep in output.\n",
    "            Defaults to ['title', 'authors', 'date', 'abstract',\n",
    "            'journal', 'doi'].\n",
    "            NOTE: If 'emails' is passed, an attempt is made to extract author\n",
    "            mail addresses.\n",
    "        start_date (str): Start date for the search. Needs to be in format:\n",
    "            YYYY/MM/DD, e.g. '2020/07/20'. Defaults to 'None', i.e. no specific\n",
    "            dates are used.\n",
    "        end_date (str): End date for the search. Same notation as start_date.\n",
    "    \"\"\"\n",
    "    papers = search_pubmed_papers(keywords, fields, start_date, end_date,\n",
    "                                  *args, **kwargs)\n",
    "    papers_pt = search_pubmed_papers(keywords+['AND preprint[pt]'],\n",
    "                                     fields, start_date, end_date, *args,\n",
    "                                     **kwargs)\n",
    "    output = papers+papers_pt\n",
    "    list_of_titles = []\n",
    "    list_of_doi = []\n",
    "    for _ in output:\n",
    "        list_of_titles.append(_[\"title\"])\n",
    "        if _[\"doi\"] is not None:\n",
    "            doi = _[\"doi\"].split(\"\\n\")[0]\n",
    "            if doi not in list_of_doi:\n",
    "                list_of_doi.append(doi)\n",
    "    if txt is True:\n",
    "        with open('pubmed_results.txt', \"w\") as f:\n",
    "            for t in list_of_titles:\n",
    "                t = t.replace('[', '')\n",
    "                t = t.replace(']', '')\n",
    "                f.write(str(t) + \"\\n\")\n",
    "        with open('dois.txt', \"w\") as f:\n",
    "            for doi in list_of_doi:\n",
    "                f.write('https://www.ncbi.nlm.nih.gov/pmc/articles/doi/'+str(doi) + \"\\n\")\n",
    "    if jsonl is True:\n",
    "        with open('pubmed_results.jsonl', \"w\") as f:\n",
    "            for paper in output:\n",
    "                f.write(str(paper) + \"\\n\")\n",
    "    return output\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # These are the keywords that are able to retrieve the most the papers in\n",
    "    # covabdab\n",
    "    covid = ['SARS-CoV-2', 'COVID-19', 'coronavirus', 'SARS-CoV', 'MERS-CoV',\n",
    "             'SARS']\n",
    "    antibody = ['antibody', 'antibodies', 'nanobody', 'MAb', 'immunoglobulin',\n",
    "                'nanobodies']\n",
    "    interaction = ['neutralizing', 'neutralize', 'neutralization', 'bind',\n",
    "                   'binding', 'inhibit', 'targeting']\n",
    "    extra = ['heavy chain',  'complementarity determining region',\n",
    "             'gene', 'epitope', 'receptor-binding domain', 'rbd',\n",
    "             'spike protein', 'VHH']\n",
    "    papers_and_preprints = pubmed_papers_and_pt(txt=True, jsonl=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f50ed7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [['SARS-CoV-2', 'COVID-19', 'coronavirus', 'SARS-CoV', 'MERS-CoV',\n",
    "        'SARS'],\n",
    "        ['antibody', 'antibodies', 'nanobody', 'immunoglobulin',\n",
    "         'nanobodies'],\n",
    "        ['neutralizing', 'neutralize', 'neutralization', 'bind', 'binding',\n",
    "         'inhibit', 'targeting', 'neutralising', 'neutralise', 'neutralisation'],\n",
    "        ['heavy chain', 'complementarity determining region', 'gene',\n",
    "         'epitope', 'receptor', 'rbd', 'spike protein', 'VHH', 'domain']]\n",
    "#papers = get_and_dump_pubmed_papers([covid,antibody,neut,structure])\n",
    "\n",
    "papers = get_and_dump_pubmed_papers([covid,\n",
    "                                     ['neutralizing-antibody','monoclonal+antibody'],\n",
    "                                     ['receptor+binding+domain','rbd'],\n",
    "                                    ['spike+protein','complementarity+determining+region','epitope']])\n",
    "dump_papers(papers, 'results.jsonl')\n",
    "list_of_titles = []\n",
    "list_of_doi = []\n",
    "for _ in papers:\n",
    "    list_of_titles.append(_[\"title\"])\n",
    "    if _[\"doi\"] != None:\n",
    "        doi = _[\"doi\"].split(\"\\n\")[0]\n",
    "        if doi not in list_of_doi:\n",
    "            list_of_doi.append(doi)\n",
    "\n",
    "with open('dois.txt', \"w\") as f:\n",
    "        for doi in list_of_doi:\n",
    "            f.write('https://doi.org/'+str(doi) + \"\\n\")\n",
    "\n",
    "with open('search_results.txt', \"w\") as f:\n",
    "        for t in list_of_titles:\n",
    "            t = t.replace('[','')\n",
    "            t = t.replace(']','')\n",
    "            f.write(str(t) + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3109cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_abs = []\n",
    "for _ in papers:\n",
    "    list_of_abs.append(_[\"abstract\"])\n",
    "dump_papers(list_of_abs,'abs.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60c9db1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('titles.txt') as f:\n",
    "    titles = f.read().splitlines()\n",
    "    \n",
    "title = []\n",
    "for t in titles:\n",
    "    t = t.split(\" - S\")[0]\n",
    "    t = t.split(\" | \")[0]\n",
    "    title.append(t)\n",
    "with open(\"titles_edited.txt\", \"w\") as f:\n",
    "        for name in title:\n",
    "            f.write(str(name) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd579563",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('titles_edited.txt') as f:\n",
    "    titles_covab = f.read().splitlines()\n",
    "    \n",
    "with open('search_results.txt') as f:\n",
    "    titles_search = f.read().splitlines()\n",
    "def get_freq(data = str):\n",
    "    words = data.split(\" \")\n",
    "    words2 = []\n",
    "    output_dict = {}\n",
    "    for _ in words:\n",
    "        if _ not in words2:\n",
    "            words2.append(_)\n",
    "    for word in words2:\n",
    "        output_dict[word] = words.count(word)\n",
    "    return output_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d6d8439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b.1.617': 10, 'point-of-care': 10, 'efficiency': 10, 'dried': 10, 'higher': 10, 'inhibitors': 10, 'reduced': 10, 'insights': 10, 'emergence': 10, 'particle': 10, 'people': 10, 'living': 10, '6': 10, 'covid-19.sars-cov-2': 10, 'population': 10, 'sarbecovirus': 10, 'glycosylated': 10, 'golden': 10, 'p.1': 10, 'glycosylation': 10, 'confers': 10, 'antibody-mediated': 10, 'vaccine-elicited': 10, 'african': 10, 'year': 10, 'ncov-19': 10, 'over': 10, 'available': 10, 'future': 10, 'validation': 10, 'mechanism': 10, 'variable': 10, 'structures': 10, 'characteristics': 10, 'antigenicity': 10, 'transmission': 10, 'inflammatory': 10, 'vector-based': 10, 'immunosorbent': 10, 'diagnosis': 10, 'homologous': 10, 'drug': 10, 'full-length': 10, 'covid': 10, 'treat': 10, 'helper': 10, 'variation': 10, 'control': 10, 'common': 10, 'detecting': 10, 'bat': 10, 'coli': 10, 'coronavirus:': 10, 'enteric': 10, 'samples': 11, 'combination': 11, 'vaccine:': 11, 'four': 11, 'kidney': 11, 'automated': 11, 'efficiently': 11, 'possible': 11, 'infections': 11, 'sensitive': 11, 'mutants': 11, 'wave': 11, 'regions': 11, 'replication': 11, 'receiving': 11, 'total': 11, 'infection.sars-cov-2': 11, 'fab': 11, 'pathogenic': 11, 'covid-19.a': 11, 'prefusion': 11, 'reactivity': 11, 'current': 11, 'outbreak': 11, 'double-blind,': 11, 'donors': 11, 'trimeric': 11, 'adults:': 11, 'genetic': 11, 'previously': 11, 'targeted': 11, 'placebo-controlled,': 11, 'studies': 11, 'fully': 11, 'fragments': 11, 'strains': 11, 'm': 11, 'virus:': 11, '(mers-cov)': 11, 'macaques': 12, 'do': 12, 'predict': 12, 'immunoassay': 12, 'sensitivity': 12, 'properties': 12, 'indirect': 12, 'milk': 12, 'candidates': 12, 'up': 12, 'bind': 12, 'cytokine': 12, 'anti-spike': 12, '3': 12, 'risk': 12, 'united': 12, 'endemic': 12, 'ii': 12, 'cross-neutralizing': 12, 'effector': 12, 'reduces': 12, 'method': 12, '(rbd)': 12, 'virus-neutralizing': 12, 'modified': 12, 'donor': 12, 'isolates': 12, 'tgev': 12, '(sars)': 12, 'key': 13, 'potency': 13, 'attachment': 13, 'flow': 13, 'without': 13, 'encoding': 13, 'receptors': 13, 'persistent': 13, 'potently': 13, 'stable': 13, 'cleavage': 13, 'hamster': 13, 'effect': 13, 'use': 13, 'one': 13, 'prevention': 13, 'lactobacillus': 13, 'cats': 13, 'detected': 13, 'mechanisms': 13, 'public': 13, 'major': 13, 'cross-reactivity': 13, 'hospitalized': 13, 'infection.a': 13, 'pseudovirus': 13, 'attenuated': 13, 'results': 13, 'sars-cov-2.a': 13, 'dromedary': 13, 'sequence': 13, 'syndrome-associated': 13, 'profiles': 14, 'application': 14, 'immunoassays': 14, 'identifies': 14, 'cocktail': 14, 'membrane': 14, 'testing': 14, 'strong': 14, 'developing': 14, 'activation': 14, 'south': 14, 'produced': 14, 'factor': 14, 'directed': 14, 'particles': 14, 'critical': 14, 'i': 14, 'blocking': 14, 'biological': 14, 'prediction': 14, 'strategy': 14, 'mers': 14, 'vesicular': 14, 'symptomatic': 15, 'delivery': 15, 'evasion': 15, '(sars-cov-2)': 15, 'administration': 15, 'versus': 15, 'n': 15, 'related': 15, 'enhancement': 15, 'induction': 15, 'patients:': 15, 'vaccines:': 15, 'non-human': 15, 'vivo': 15, 'correlates': 15, 'adaptive': 15, 'immunological': 15, 'improves': 15, 'determinants': 15, 'correlate': 15, 'infectivity': 15, 'functions': 15, 'diagnostic': 15, 'function': 15, 'influenza': 15, 'changes': 15, 'stomatitis': 15, 'phage': 15, 'immunodominant': 15, 'diverse': 16, 'inhibits': 16, 'mutational': 16, 'chadox1': 16, 'doses': 16, 'serologic': 16, 'lung': 16, 'adults': 16, 'features': 16, '-': 16, 'containing': 16, 'immunogenic': 16, 'three': 16, 'systemic': 17, 'linear': 17, 'patient': 17, 'case': 17, 'cross-reactive': 17, 'impact': 17, 'vaccine-induced': 17, 'neutralizes': 17, 'kinetics': 17, 'pandemic': 17, 'longitudinal': 17, 'nanobody': 17, 'adjuvant': 17, 'children': 17, 'platform': 17, 'd614g': 17, 'effects': 17, 'adenovirus': 17, 'global': 17, 'pseudotyped': 17, 'provides': 17, 'fragment': 17, 'polyclonal': 18, 'titers': 18, 'lethal': 18, 'enhanced': 18, 'virus-like': 18, 'type': 18, 'sars-cov-2-specific': 18, 'strategies': 18, 'domains': 18, 'igm': 18, 'review': 18, 'durable': 18, 'persistence': 18, 'cov-2': 18, 'nanoparticles': 18, 'therapeutics': 18, 'effective': 19, 'assessment': 19, 'detect': 19, 'seroprevalence': 19, 'correlation': 19, 'transplant': 19, 'n-terminal': 19, 'derived': 19, 'reveal': 19, 'multiplex': 19, 'protect': 19, 'vitro': 19, 'display': 19, 'evidence': 19, 'recognition': 19, 'amino': 19, 'enzyme': 20, 'neutralising': 20, 'conserved': 20, 'high-throughput': 20, 'mrna-1273': 20, 'resistance': 20, 'screening': 20, 'approach': 20, 'intranasal': 21, 'interaction': 21, 'safety': 21, 'system': 21, 'delta': 21, 'commercial': 21, 'block': 21, 'b.1.351': 21, 'transgenic': 21, 'peptides': 21, 'conformational': 21, 'within': 21, 'mutation': 21, 'surrogate': 21, 'viruses': 21, 'nonhuman': 21, 'evolution': 22, 'iga': 22, 'prospective': 22, 'vector': 22, 'protein:': 22, 'broad': 22, 'antibodies:': 22, 'fc': 22, 'quantitative': 22, 'sera': 22, 'asymptomatic': 22, 'antibody-dependent': 22, 'peplomer': 22, 'surface': 23, 'broadly': 23, 'through': 23, 'antiviral': 23, 'challenge': 23, 'elicit': 23, 'model': 23, 'identification': 23, 'isolated': 23, 'robust': 23, 'via': 23, 'sites': 23, 'synthetic': 23, 'vaccinia': 23, 'vaccinated': 24, 'healthy': 24, 'distinct': 24, 'mapping': 24, 'interactions': 24, 'care': 24, 'production': 24, 'b.1.1.7': 24, 'sars-cov-2:': 24, 'animal': 24, 'acid': 24, 'region': 24, 'severity': 24, 'structure': 24, 'recovered': 24, 'expressed': 24, 'peritonitis': 24, 'nanobodies': 25, 'b-cell': 25, 'targets': 25, 'syrian': 25, 'comparison': 25, 'affinity': 25, 'antigens': 25, 'therapy': 25, 'nanoparticle': 25, 'peptide': 25, '2019': 25, 'serology': 26, 'individuals': 26, 'immunoglobulin': 26, 'months': 26, 'bovine': 26, 'inhibition': 26, 'avian': 26, 'host': 27, 'workers': 27, 'mucosal': 27, 'profiling': 28, 'health': 28, 'target': 29, 'concern': 29, 't-cell': 29, 'early': 29, 'circulating': 29, 'rna': 29, 'design': 29, 's2': 29, 'rhesus': 30, 'into': 30, 'test': 31, 'natural': 31, 'elisa': 31, 'mild': 32, 'induce': 32, 'cohort': 32, 'healthcare': 32, 'first': 32, 'covid-19:': 32, 'site': 32, 'neutralize': 32, 'coronaviruses': 32, 'treatment': 33, 'elicited': 33, 'role': 33, 'dynamics': 33, 'gene': 34, 'levels': 35, 'inactivated': 36, 'evaluation': 36, 'blood': 37, 'different': 38, 'basis': 38, '1': 38, 'feline': 38, 'antigen': 39, 'highly': 39, 'dna': 39, 'phase': 39, 'multiple': 40, 'memory': 40, 'functional': 40, 'implications': 40, 'infected': 40, 'expression': 41, 'strain': 41, 'molecular': 41, 'rapid': 42, 'fusion': 42, 'but': 42, 'entry': 42, 'high': 43, 'associated': 43, 'immunization': 44, 'new': 44, 'dose': 45, 'study': 45, 'reveals': 47, 'following': 47, 'serum': 47, 'induced': 48, 'structural': 48, 'nucleocapsid': 50, 'among': 50, 'antigenic': 50, 'single': 51, 'emerging': 51, 'assays': 51, 'expressing': 53, 'candidate': 53, 'hepatitis': 55, 'activity': 56, 'mutations': 57, 'escape': 57, 'elicits': 57, 'cellular': 58, 'during': 58, 'based': 58, 'murine': 58, 'mouse': 58, 'potential': 60, 'clinical': 60, 'development': 61, 'protects': 62, 't': 63, 'therapeutic': 63, 'two': 65, 'serological': 65, 'efficacy': 65, 'middle': 66, 'mers-cov': 67, 'anti-sars-cov-2': 67, 'b': 68, 'characterization': 68, 'mice': 69, 'ace2': 70, 's1': 71, 's': 72, 'sars-cov': 73, 'bronchitis': 73, 'plasma': 74, 'epitope': 74, 'subunit': 74, 'cells': 75, 'rbd': 76, 'protection': 76, 'variant': 77, 'specific': 77, 'east': 79, 'protective': 80, 'targeting': 80, 'immunogenicity': 81, 'assay': 83, 'proteins': 83, '2': 83, 'induces': 84, 'bnt162b2': 87, 'potent': 89, 'diarrhea': 90, 'gastroenteritis': 90, 'epitopes': 92, 'epidemic': 92, 'transmissible': 93, 'igg': 99, 'glycoprotein': 101, 'disease': 103, 'novel': 104, 'vaccines': 104, 'analysis': 105, 'sars': 106, 'detection': 107, 'infectious': 110, 'humoral': 111, 'vaccination': 111, 'cell': 114, 'immunity': 117, 'viral': 123, 'porcine': 124, 'mrna': 128, 'recombinant': 138, 'after': 140, 'patients': 150, 'receptor-binding': 154, 'convalescent': 155, 'variants': 158, 'receptor': 171, 'acute': 192, 'severe': 194, 'response': 199, 'immune': 210, 'neutralization': 211, 'infection': 215, 'syndrome': 230, 'binding': 234, 'monoclonal': 236, 'domain': 254, 'responses': 276, 'human': 277, 'respiratory': 284, 'virus': 366, 'covid-19': 457, 'vaccine': 473, 'neutralizing': 483, 'coronavirus': 488, 'protein': 507, 'antibodies': 632, 'antibody': 646, 'spike': 780, 'sars-cov-2': 1634}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da12c7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'potently': 5, 'efficacy': 5, 'sars-cov': 5, 'variants': 5, 'highly': 5, 'recognition': 5, 'patients': 5, 'specific': 5, 'development': 5, 'mice': 6, 'severe': 6, 'therapeutic': 6, 'responses': 6, 'multiple': 6, 'nucleocapsid': 6, 'acute': 7, 'domain': 8, 'block': 8, 'mers-cov': 8, 'epitope': 8, 'infection': 8, 'nanobody': 8, 'covid-19': 9, 'nanobodies': 9, 'neutralize': 10, 'basis': 10, 'syndrome': 10, 'receptor': 10, 'respiratory': 11, 'convalescent': 11, 'protein': 13, 'targeting': 13, 'coronavirus': 16, 'binding': 20, 'neutralization': 21, 'potent': 27, 'monoclonal': 28, 'spike': 34, 'human': 44, 'antibody': 46, 'neutralizing': 58, 'antibodies': 58, 'sars-cov-2': 95}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "162de323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113705\n"
     ]
    }
   ],
   "source": [
    "abs_cov = ''\n",
    "for _ in titles_covab:\n",
    "    for elem in papers:\n",
    "        if _.lower() == elem['title'].lower():\n",
    "            if elem['abstract'] is not None:\n",
    "                abs_cov = abs_cov + ' ' + elem['abstract'].lower()\n",
    "                \n",
    "abs = ''\n",
    "\n",
    "for elem in papers:\n",
    "    if elem['abstract'] is not None:\n",
    "        abs = abs + ' ' +  elem['abstract'].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9d194c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "abs_cov = abs_cov.replace('.','')\n",
    "abs_cov = abs_cov.replace('(','')\n",
    "abs_cov = abs_cov.replace(')','')\n",
    "abs_cov = abs_cov.replace(',','')\n",
    "print(len(nltk.sent_tokenize(abs_cov)))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3032ef14",
   "metadata": {},
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "def extract_phrases(text, phrase_counter, length):\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        words = nltk.word_tokenize(sent)\n",
    "        for phrase in ngrams(words, length):\n",
    "            phrase_counter[phrase] += 1\n",
    "\n",
    "phrase_counter = Counter()\n",
    "\n",
    "extract_phrases(abs_cov, phrase_counter, 4)\n",
    "\n",
    "most_common_phrases = phrase_counter.most_common(100)\n",
    "print(most_common_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37a4141c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "def extract_phrases(text, phrase_counter, length):\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        words = nltk.word_tokenize(sent)\n",
    "        for phrase in ngrams(words, length):\n",
    "            phrase_counter[phrase] += 1\n",
    "\n",
    "phrase_counter = Counter()\n",
    "\n",
    "extract_phrases(abs, phrase_counter, 5)\n",
    "\n",
    "most_common_phrases = phrase_counter.most_common(100)\n",
    "print(most_common_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03794df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['SARS-CoV-2', 'COVID-19', 'coronavirus', 'SARS-CoV', 'MERS-CoV', 'SARS'], ['antibody', 'antibodies', 'nanobody', 'immunoglobulin', 'MAb', 'nanobodies'], ['neutralizing', 'neutralize', 'neutralization', 'bind', 'binding', 'inhibit', 'targeting'], ['heavy chain', 'complementarity determining region', 'gene', 'epitope', 'receptor-binding domain', 'rbd', 'spike protein', 'VHH']]\n",
      "[['SARS-CoV-2', 'COVID-19', 'coronavirus', 'SARS-CoV', 'MERS-CoV', 'SARS'], ['antibody', 'antibodies', 'nanobody', 'immunoglobulin', 'MAb', 'nanobodies'], ['neutralizing', 'neutralize', 'neutralization', 'bind', 'binding', 'inhibit', 'targeting'], ['heavy chain', 'complementarity determining region', 'gene', 'epitope', 'receptor-binding domain', 'rbd', 'spike protein', 'VHH'], 'AND preprint[pt]']\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Union\n",
    "from paperscraper.pubmed import get_query_from_keywords_and_date\n",
    "from paperscraper.pubmed import get_pubmed_papers\n",
    "\n",
    "\n",
    "def search_pubmed_papers(\n",
    "    keywords: List[Union[str, List[str]]]\n",
    "    = [['SARS-CoV-2', 'COVID-19', 'coronavirus', 'SARS-CoV', 'MERS-CoV',\n",
    "        'SARS'],\n",
    "        ['antibody', 'antibodies', 'nanobody', 'immunoglobulin', 'MAb',\n",
    "         'nanobodies'],\n",
    "        ['neutralizing', 'neutralize', 'neutralization', 'bind', 'binding',\n",
    "         'inhibit', 'targeting'],\n",
    "        ['heavy chain', 'complementarity determining region', 'gene',\n",
    "         'epitope', 'receptor-binding domain', 'rbd', 'spike protein', 'VHH']],\n",
    "    fields: List = [\"title\", \"authors\", \"date\", \"abstract\", \"journal\", \"doi\"],\n",
    "    start_date: str = \"None\",\n",
    "    end_date: str = \"None\",\n",
    "    *args,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Combines get_pubmed_papers and dump_papers.\n",
    "    For default setting, just import this function and use\n",
    "    search_pubmed_papers()\n",
    "    Returns:\n",
    "        A list of dictionaries, each containing the paper's\n",
    "         [\"title\", \"authors\", \"date\", \"abstract\", \"journal\", \"doi\"]\n",
    "\n",
    "    Args:\n",
    "        keywords (List[Union[str, List[str]]]): List of keywords to request\n",
    "            pubmed API. The outer list level will be considered as AND\n",
    "            separated keys, the inner level as OR separated.\n",
    "        fields (List, optional): List of strings with fields to keep in output.\n",
    "            Defaults to ['title', 'authors', 'date', 'abstract',\n",
    "            'journal', 'doi'].\n",
    "            NOTE: If 'emails' is passed, an attempt is made to extract author\n",
    "            mail addresses.\n",
    "        start_date (str): Start date for the search. Needs to be in format:\n",
    "            YYYY/MM/DD, e.g. '2020/07/20'. Defaults to 'None', i.e. no specific\n",
    "            dates are used.\n",
    "        end_date (str): End date for the search. Same notation as start_date.\n",
    "    \"\"\"\n",
    "    # Translate keywords into query.\n",
    "    print(keywords)\n",
    "    query = get_query_from_keywords_and_date(\n",
    "        keywords, start_date=start_date, end_date=end_date\n",
    "    )\n",
    "    papers = get_pubmed_papers(query, fields, *args, **kwargs)\n",
    "    return papers\n",
    "\n",
    "\n",
    "def dump_papers(papers, filepath: str) -> None:\n",
    "    \"\"\"\n",
    "    Receives a list of dicts, one dict per paper and dumps it into a .jsonl\n",
    "    file with one paper per line.\n",
    "    Args:\n",
    "        papers (list[dict]): List of papers\n",
    "        filepath (str): Path to dump the papers.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(filepath, \"w\") as f:\n",
    "        for paper in papers:\n",
    "            f.write(str(paper) + \"\\n\")\n",
    "\n",
    "\n",
    "def pubmed_papers_and_pt(\n",
    "    keywords: List[Union[str, List[str]]]\n",
    "    = [['SARS-CoV-2', 'COVID-19', 'coronavirus', 'SARS-CoV', 'MERS-CoV',\n",
    "        'SARS'],\n",
    "        ['antibody', 'antibodies', 'nanobody', 'immunoglobulin', 'MAb',\n",
    "         'nanobodies'],\n",
    "        ['neutralizing', 'neutralize', 'neutralization', 'bind', 'binding',\n",
    "         'inhibit', 'targeting'],\n",
    "        ['heavy chain', 'complementarity determining region', 'gene',\n",
    "         'epitope', 'receptor-binding domain', 'rbd', 'spike protein', 'VHH']],\n",
    "    fields: List = [\"title\", \"authors\", \"date\", \"abstract\", \"journal\", \"doi\"],\n",
    "    start_date: str = \"None\",\n",
    "    end_date: str = \"None\",\n",
    "    txt: bool = False,\n",
    "    jsonl: bool = False,\n",
    "    *args,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Search for papers and preprints on PubMed\n",
    "    Returns:\n",
    "        A list of dictionaries, each containing the paper's\n",
    "         [\"title\", \"authors\", \"date\", \"abstract\", \"journal\", \"doi\"]\n",
    "        AND/OR files containing relevant information\n",
    "\n",
    "    Args:\n",
    "        keywords (List[Union[str, List[str]]],optional): List of keywords to\n",
    "            request pubmed API. The outer list level will be considered as AND\n",
    "            separated keys, the inner level as OR separated.\n",
    "        fields (List, optional): List of strings with fields to keep in output.\n",
    "            Defaults to ['title', 'authors', 'date', 'abstract',\n",
    "            'journal', 'doi'].\n",
    "            NOTE: If 'emails' is passed, an attempt is made to extract author\n",
    "            mail addresses.\n",
    "        start_date (str): Start date for the search. Needs to be in format:\n",
    "            YYYY/MM/DD, e.g. '2020/07/20'. Defaults to 'None', i.e. no specific\n",
    "            dates are used.\n",
    "        end_date (str): End date for the search. Same notation as start_date.\n",
    "    \"\"\"\n",
    "    papers = search_pubmed_papers(keywords, fields, start_date, end_date,\n",
    "                                  *args, **kwargs)\n",
    "    papers_pt = search_pubmed_papers(keywords+['AND preprint[pt]'],\n",
    "                                     fields, start_date, end_date, *args,\n",
    "                                     **kwargs)\n",
    "    output = papers+papers_pt\n",
    "    list_of_titles = []\n",
    "    list_of_doi = []\n",
    "    for _ in output:\n",
    "        list_of_titles.append(_[\"title\"])\n",
    "        if _[\"doi\"] is not None:\n",
    "            doi = _[\"doi\"].split(\"\\n\")[0]\n",
    "            if doi not in list_of_doi:\n",
    "                list_of_doi.append(doi)\n",
    "    if txt is True:\n",
    "        with open('pubmed_titles.txt', \"w\") as f:\n",
    "            for t in list_of_titles:\n",
    "                t = t.replace('[', '')\n",
    "                t = t.replace(']', '')\n",
    "                f.write(str(t) + \"\\n\")\n",
    "        with open('pubmed_dois.txt', \"w\") as f:\n",
    "            for doi in list_of_doi:\n",
    "                f.write('https://doi.org/'+str(doi) + \"\\n\")\n",
    "    if jsonl is True:\n",
    "        with open('pubmed_results.jsonl', \"w\") as f:\n",
    "            for paper in output:\n",
    "                f.write(str(paper)+ \"\\n\")\n",
    "    return output\n",
    "\n",
    "pps = pubmed_papers_and_pt(txt=True, jsonl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "724de143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4364\n"
     ]
    }
   ],
   "source": [
    "print(len(pps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7eef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = get_and_dump_pubmed_papers([covid,\n",
    "                                     ['neutralizing-antibody','monoclonal+antibody'],\n",
    "                                     ['receptor+binding+domain','rbd'],\n",
    "                                    ['spike+protein','complementarity+determining+region','epitope']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
